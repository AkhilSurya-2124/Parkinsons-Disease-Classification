import pandas as pd
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Perceptron
import matplotlib.pyplot as plt
import numpy as np

#read the data set change the path as required
df = pd.read_csv("C:\\Users\\Akhil\\Downloads\\pk.csv")
#df.head(-10)
#the status column tells if the patient is diagnosed with Parkinsons' Disease or not
# status is 1 if patient is positive and 0 otherwise

print("Pakinsons Disease Classification")

X = df.drop('status',axis=1)# get all columns except status
y= df['status']#get the status of patients in a variable
#cols = X.columns
#print(cols)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=10)
#the above statement splits given data set into two parts for training and for testing
#test_size is the ratio on which the data set will be divided
X_train=X_train.drop("name",axis=1)
X_test=X_test.drop('name',axis=1)
#we dropped name column because the result will not depend on the patients' name and its not useful
#print(X_train)
#print(X_test)

########################
print("SVM")
SVCL = SVC(C=100,gamma=0.002)
SVCL.fit(X_train , y_train)

svc_train_predict = SVCL.predict(X_train)
print("Accuracy of training data:",format((accuracy_score(y_train,svc_train_predict)*100),".4f"))

svc_test_predict = SVCL.predict(X_test)
print("Accuracy of testing data",format((accuracy_score(y_test,svc_test_predict)*100),".4f"))
########################

#Perceptron
print("Perceptron")
perceptron=Perceptron()
train_predictPercep=perceptron.fit(X_train,y_train)
test_predictPercep=perceptron.predict(X_test)
train_predictPercep=train_predictPercep.predict(X_train)

print("Accuracy of training data:",format((accuracy_score(y_train,train_predictPercep)*100),".4f"))

print("Accuracy of testing data:",format((accuracy_score(y_test,test_predictPercep)*100),".4f"))

########################

c=df.columns[0:]
Y=df[c[17]].values
#print(Y)
df1=df.drop(['status','name'],axis=1)
c=df1.columns[0:]
X=df1[c[0:]].values
#print(X.shape)
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=1000)
#########################
print("LVQ")
W=np.random.random((2,X.shape[1]))
def LVQ(x,tar):
    lr=0.5
    d=[0,0]
    e=1
    while(e<=1000):
      for i in range(x.shape[0]):
        for j in range(W.shape[0]):
          d[j]=np.sum((x[i,:]-W[j,:])**2)
          d[j]=d[j]**0.5
        #print(d)
        if(d[0]<d[1]):
          t=0
        else:
          t=1
        if(t==tar[i]):
          W[t,:]+=lr*(x[i,:]-W[t,:])
        else:
           W[t,:]-=lr*(x[i,:]-W[t,:])
      e+=1
      #lr=0.5*lr
    return W
W=LVQ(X_train,y_train)
print(W)
def LVQt(X,Y,W):
    d=[0,0]
    res=np.zeros(Y.shape)
    for i in range(X.shape[0]):
        for j in range(W.shape[0]):
            d[j]=np.sum((X[i,:]-W[j,:])**2)
        if d[0]<d[1]:
            res[i]=0
        else:
            res[i]=1
    return res
y_pred=LVQt(X_test,y_test,W)
print(y_pred)
print(y_test)
from sklearn.metrics import accuracy_score
print("Accuracy of training data:",format((accuracy_score(y_train,y_pred)*100),".4f"))
print("Accuracy of testing data:",format((accuracy_score(y_test,y_pred)*100),".4f"))

####################

print("SVM")
W=np.zeros((2,X.shape[1]))
def SOM(x,y):
    lr=0.5
    d=[0,0]
    e=1
    res=np.zeros(y.shape)
    while(e<=3):
      for i in range(x.shape[0]):
        for j in range(W.shape[0]):
          d[j]=np.sum((x[i,:]-W[j,:])**2)
          d[j]=d[j]**0.5
        if(d[0]<d[1]):
          t=0
          res[i]=0
        else:
          t=1
          res[i]=1
        W[t,:]+=lr*(x[i,:]-W[t,:])
      e+=1
      lr=0.5*lr
    return res
som=SOM(X_train,y_train)
print("Accuracy of testing data:",format((accuracy_score(y_test,som)*100),".4f"))
